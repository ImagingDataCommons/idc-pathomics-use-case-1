{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Investigation of the Coudray Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import openslide \n",
    "import openslide.deepzoom\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a svs file with openslide into a DeepZoomGenerator \n",
    "\n",
    "# here parameters like the number of levels and the downsampling factor can be specified\n",
    "image = openslide.OpenSlide('/mnt/gaia/ICIDC/data_coudray/858bf199-5962-4d6e-a059-4d33b04edc17/TCGA-18-3415-01A-01-TS1.d922ab4a-e5c2-4b49-a173-964e569e3985.svs')\n",
    "\n",
    "# here parameters like the tile size can be specified\n",
    "image_slide = openslide.deepzoom.DeepZoomGenerator(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some information about the observed image\n",
    "print(image.level_downsamples)\n",
    "print(image_slide.level_count) # number of deepzoom levels for the slide\n",
    "print(image_slide.tile_count) # number of tiles for the slide\n",
    "print(image_slide.level_tiles) # (tiles_x, tiles_y) for each zoom level\n",
    "print(image_slide.level_dimensions) # (pixel_x, pixel_y) for each zoom level\n",
    "print(image_slide.get_dzi('png')) \n",
    "print(image_slide.get_tile(level=1, address=(0,0)))\n",
    "print(image_slide.get_tile_coordinates(level=1, address=(0,0)))\n",
    "print(image_slide.get_tile_dimensions(level=1, address=(0,0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a single tile \n",
    "tile = image_slide.get_tile(level=6, address=(0,0))\n",
    "grey = tile.convert('L')\n",
    "bw = grey.point(lambda x: 0 if x < 220 else 1, mode='F') # F -> 32-bit floating point values\n",
    "bw_visualize = grey.point(lambda x: 0 if x < 220 else 1, mode='1') # 1 -> 1-bit pixels\n",
    "\n",
    "plt.imshow(bw_visualize)\n",
    "print('average background', np.average(np.array(np.asarray(bw_visualize))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(np.asarray(bw)))\n",
    "print(np.array(np.asarray(bw_visualize)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to create a generator for model training from a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_set import Dataset\n",
    "test_dataset = Dataset('/output_data/test_dataset.csv')\n",
    "gen = test_dataset.get_generator(batch_size=8, shuffle=True, infinite=True)\n",
    "\n",
    "for _ in range((len(test_dataset)//8) * 2):\n",
    "    print(next(gen)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to visualize a patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_set import Dataset\n",
    "test_dataset = Dataset('/output_data/test_dataset.csv')\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 5))\n",
    "\n",
    "# either direct access of data point\n",
    "data_point = test_dataset.data_points[0]\n",
    "ax1.imshow(data_point.get_patch())\n",
    "\n",
    "# or from the generator\n",
    "\n",
    "gen = test_dataset.get_generator()\n",
    "patch = next(gen)[0]\n",
    "ax2.imshow(patch[0,...]) # patch has batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get a short dummy testset csv file by taking one (random) path from each patient using bash \n",
    "uniq -d -w 12 <csv_file> > <output_file>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the training loss from a history.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "with open(path, 'r') as json_file: \n",
    "    history = json.load(json_file)\n",
    "    plt.plot(history.history['loss'], label='training loss')\n",
    "    plt.plot(history.history['val_loss'], label='validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('cross entropy loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
